/**
 * Response Generator Module
 * 
 * Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙˆÙ„ Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ÙˆØ¯ AI ÙˆØ¨Ù†Ø§Ø¡ Ø§Ù„Ù€ prompts
 * ØªÙ… Ù†Ù‚Ù„Ù‡ Ù…Ù† aiAgentService.js Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„ØµÙŠØ§Ù†Ø©
 */

const { getSharedPrismaClient, safeQuery } = require('../sharedDatabase');
const aiResponseMonitor = require('../aiResponseMonitor');
const productExtractor = require('./productExtractor');
// âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ constants Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ
const {
  DEFAULT_AI_SETTINGS,
  TOKEN_LIMITS_BY_TYPE,
  RETRY_TOKEN_MULTIPLIERS,
  TEMPERATURE_BY_TYPE,
  SAMPLING_BY_TYPE,
  RESPONSE_VALIDATION,
} = require('./aiConstants');
const { buildPromptFromRules, getDefaultRules } = require('./responseRulesConfig');
const AIProviderFactory = require('./providers/AIProviderFactory');
const PromptService = require('./promptService');
const fewShotService = require('./fewShotService'); // ğŸ“ Few-Shot Learning

// âœ… Context Resolvers (Phase 3 Decoupling)
const ShippingResolver = require('./resolvers/ShippingResolver');
const RagResolver = require('./resolvers/RagResolver');

const CustomerResolver = require('./resolvers/CustomerResolver');

// âœ… Queue Service (Async Logging)
const queueService = require('../queueService');
// âœ… Semantic Cache Service
const semanticCacheService = require('./semanticCacheService');



class ResponseGenerator {
  constructor(aiAgentService) {
    // âœ… Ø­ÙØ¸ reference Ù„Ù€ aiAgentService Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
    // âœ… FIX 1: Ù†Ø¸Ø§Ù… ØªØªØ¨Ø¹ Ø¹Ø§Ù„Ù…ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¬Ø±Ø¨Ø© - Ø§Ù„Ø¢Ù† ÙŠØ³ØªØ®Ø¯Ù… stateManager (Redis)
    // Removed In-Memory Map
    this.aiAgentService = aiAgentService;

    // âœ… ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¬Ø±Ø¨Ø© Ù„ÙƒÙ„ Ø¬Ù„Ø³Ø©
    this.globalTriedModels = new Map();
  }

  /**
   * Stop and cleanup resources
   */
  stop() {
    // Cleanup globalTriedModels to prevent memory leaks
    if (this.globalTriedModels) {
      this.globalTriedModels.clear();
    }
  }

  /**
   * Cleanup old sessions from globalTriedModels (run periodically)
   */
  cleanupOldSessions() {
    const MAX_AGE_MS = 5 * 60 * 1000; // 5 minutes
    const now = Date.now();
    for (const [sessionId, data] of this.globalTriedModels.entries()) {
      if (now - data.timestamp > MAX_AGE_MS) {
        this.globalTriedModels.delete(sessionId);
      }
    }
  }

  /**
   * âœ… Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ØªØµØ§Ø¹Ø¯ÙŠ Ù…Ø¹ Jitter
   * Exponential Backoff: 1s â†’ 2s â†’ 4s â†’ 8s (max 10s)
   * Jitter: +0-500ms Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„ØªØ¬Ù†Ø¨ thundering herd
   * @param {number} attempt - Ø±Ù‚Ù… Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© (0-indexed)
   * @returns {number} - ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø§Ù„Ù…Ù„Ù„ÙŠ Ø«Ø§Ù†ÙŠØ©
   */
  getBackoffDelay(attempt) {
    const baseDelay = 1000; // 1 Ø«Ø§Ù†ÙŠØ©
    const maxDelay = 10000; // 10 Ø«ÙˆØ§Ù†ÙŠ ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
    const exponentialDelay = Math.min(baseDelay * Math.pow(2, attempt), maxDelay);
    const jitter = Math.floor(Math.random() * 500); // 0-500ms Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
    return exponentialDelay + jitter;
  }

  /**
   * âœ¨ Ø¨Ù†Ø§Ø¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
   */
  async buildGenerationConfig(companyId, messageContext = {}) {
    try {
      // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª AI Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      const settings = await this.aiAgentService.getSettings(companyId);

      // âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ… Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„ØªÙŠ ØªØ£ØªÙŠ Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©)
      // âš ï¸ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙÙ‚Ø· (AIManagement.tsx)
      const messageType = messageContext?.messageType || 'general';

      // âœ… FIX: Ø§Ø³ØªØ®Ø¯Ø§Ù… ?? Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† || Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ØµÙØ±ÙŠØ©
      // Ø§Ù„Ù‚ÙŠÙ…Ø© ØªØ£ØªÙŠ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„ØªÙŠ Ø­ÙØ¸ØªÙ‡Ø§ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©)
      const baseConfig = {
        temperature: settings.aiTemperature ?? DEFAULT_AI_SETTINGS.TEMPERATURE,
        topK: settings.aiTopK ?? DEFAULT_AI_SETTINGS.TOP_K,
        topP: settings.aiTopP ?? DEFAULT_AI_SETTINGS.TOP_P,
        // âš ï¸ Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…ØµØ¯Ø±Ù‡Ø§ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©) - fallback Ù…Ù† constants ÙÙ‚Ø·
        maxOutputTokens: settings.aiMaxTokens ?? DEFAULT_AI_SETTINGS.MAX_OUTPUT_TOKENS,
      };

      // âœ… Logging Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
      if (settings.aiMaxTokens !== null && settings.aiMaxTokens !== undefined) {
        console.log(`ğŸ” [AI-CONFIG] Using aiMaxTokens from database: ${settings.aiMaxTokens} (companyId: ${companyId})`);
      } else {
        console.log(`ğŸ” [AI-CONFIG] Using default aiMaxTokens: ${DEFAULT_AI_SETTINGS.MAX_OUTPUT_TOKENS} (companyId: ${companyId})`);
      }

      // âœ… Allow overriding temperature and maxOutputTokens from messageContext
      if (messageContext?.temperature !== undefined) {
        baseConfig.temperature = messageContext.temperature;
      }
      if (messageContext?.maxTokens !== undefined) {
        baseConfig.maxOutputTokens = messageContext.maxTokens;
      }

      // âœ… ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ù† constants
      const typeTemperature = TEMPERATURE_BY_TYPE[messageType];
      if (typeTemperature !== null && typeTemperature !== undefined && messageContext?.temperature === undefined) {
        baseConfig.temperature = typeTemperature;
      } else if ((messageType === 'greeting' || messageType === 'casual_chat') && messageContext?.temperature === undefined) {
        // Ù„Ù„ØªØ­ÙŠØ§Øª ÙˆØ§Ù„Ø¯Ø±Ø¯Ø´Ø©: Ø¥Ø¨Ø¯Ø§Ø¹ Ø£Ø¹Ù„Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹
        baseConfig.temperature = Math.min(baseConfig.temperature + 0.1, 0.9);
      }

      // âœ… ØªØ·Ø¨ÙŠÙ‚ Token Limits Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø© (ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
      // âš ï¸ Ù„Ø§ Ù†Ø³ØªØ¨Ø¯Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Ù…Ø«Ù„ 1280) Ø¨Ù‚ÙŠÙ…Ø© Ù…Ù† TOKEN_LIMITS_BY_TYPE
      // Ù†Ø³ØªØ®Ø¯Ù… TOKEN_LIMITS_BY_TYPE ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‡ÙŠ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (2048) Ø£Ùˆ null
      if (messageContext?.maxTokens === undefined) {
        // âœ… ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‡ÙŠ Ù†ÙØ³ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø£Ùˆ null
        // Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù… ÙŠØºÙŠØ± Ø§Ù„Ù‚ÙŠÙ…Ø© ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
        const isDefaultValue = settings.aiMaxTokens === null ||
          settings.aiMaxTokens === undefined ||
          settings.aiMaxTokens === DEFAULT_AI_SETTINGS.MAX_OUTPUT_TOKENS;

        if (isDefaultValue) {
          // âœ… ÙÙ‚Ø· ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø© Ù†Ø³ØªØ®Ø¯Ù… TOKEN_LIMITS_BY_TYPE
          const typeTokenLimit = TOKEN_LIMITS_BY_TYPE[messageType];
          if (typeTokenLimit) {
            baseConfig.maxOutputTokens = typeTokenLimit;
          }
        }
        // âœ… Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØªÙ„ÙØ© (Ù…Ø«Ù„ 1280 Ø£Ùˆ 512)ØŒ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙƒÙ…Ø§ Ù‡ÙŠ
        // Ù„Ø§ Ù†ØºÙŠØ± baseConfig.maxOutputTokens ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©
      }

      // âœ… ØªØ·Ø¨ÙŠÙ‚ Sampling Settings Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
      const typeSampling = SAMPLING_BY_TYPE[messageType];
      if (typeSampling) {
        baseConfig.topK = typeSampling.topK;
        baseConfig.topP = typeSampling.topP;
      }

      //console.log(`ğŸ›ï¸ [AI-CONFIG] Using generation config:`, baseConfig);
      return baseConfig;

    } catch (error) {
      console.error('âŒ [AI-CONFIG] Error building generation config:', error);
      // âœ… Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ù† constants Ø¹Ù†Ø¯ Ø­Ø¯ÙˆØ« Ø®Ø·Ø£
      return {
        temperature: DEFAULT_AI_SETTINGS.TEMPERATURE,
        topK: DEFAULT_AI_SETTINGS.TOP_K,
        topP: DEFAULT_AI_SETTINGS.TOP_P,
        maxOutputTokens: DEFAULT_AI_SETTINGS.MAX_OUTPUT_TOKENS,
      };
    }
  }

  /**
   * Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ prompt Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)
   */
  /**
   * Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ prompt Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
   * âœ… ASYNC: ØªÙ… ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ø¯Ø§Ù„Ø© ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø© Ù„Ø¯Ø¹Ù… Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
   */
  /**
   * Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ prompt Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
   * âœ… Phase 3: Uses Resolvers instead of formatting logic
   */
  async buildPrompt(customerMessage, companyPrompts, conversationMemory, ragData, customerData, messageData) {
    let prompt = '';
    const companyId = customerData?.companyId || messageData?.companyId;

    // 1. System Personality & Rules
    // ------------------------------------------------------------------
    const personalityPromptTrimmed = companyPrompts?.personalityPrompt?.trim() || '';
    const isPlaceholder = personalityPromptTrimmed.startsWith('# ÙŠØ¬Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯');

    if (!companyPrompts || !personalityPromptTrimmed || isPlaceholder) {
      prompt += await PromptService.getTemplate(null, 'system_personality');
    } else {
      prompt += `${personalityPromptTrimmed}\n\n`;
    }

    if (companyPrompts?.responseRules) {
      try {
        const rules = typeof companyPrompts.responseRules === 'string'
          ? JSON.parse(companyPrompts.responseRules)
          : companyPrompts.responseRules;
        prompt += buildPromptFromRules(rules);
      } catch (e) {
        console.warn('âš ï¸ [RESPONSE-RULES] Failed to parse rules, using defaults');
        prompt += buildPromptFromRules(getDefaultRules());
      }
    } else {
      prompt += buildPromptFromRules(getDefaultRules());
    }

    // 2. Customer Context (via CustomerResolver)
    // ------------------------------------------------------------------
    try {
      const customerProfile = CustomerResolver.resolveProfile(customerData, conversationMemory);
      prompt += await PromptService.getTemplate(null, 'system_customer_info', customerProfile);
    } catch (e) {
      console.error('âŒ [RESOLVER-ERROR] CustomerResolver failed:', e.message);
      // Fallback: Skip customer info, maybe add generic "Valued Customer" if needed
    }

    // 3. Shipping Context (via ShippingResolver)
    // ------------------------------------------------------------------
    try {
      const shippingData = await ShippingResolver.resolve(customerMessage, companyId, conversationMemory);

      if (shippingData && shippingData.shippingInfo) {
        prompt += await PromptService.getTemplate(companyId, 'shipping_response', shippingData.shippingInfo);
      } else if (shippingData && shippingData.isAsking && shippingData.foundGovernorate && !shippingData.shippingInfo) {
        prompt += await PromptService.getTemplate(companyId, 'no_shipping_found', { governorate: shippingData.foundGovernorate });
      } else if (shippingData && shippingData.isAsking) {
        prompt += await PromptService.getTemplate(null, 'system_shipping_alert', { customerMessage });
      }
    } catch (e) {
      console.error('âŒ [RESOLVER-ERROR] ShippingResolver failed:', e.message);
    }

    // 4. Conversation History (via CustomerResolver)
    // ------------------------------------------------------------------
    try {
      const historyData = CustomerResolver.resolveHistory(conversationMemory);
      if (historyData.hasHistory) {
        prompt += await PromptService.getTemplate(null, 'system_conversation_header');

        for (const item of historyData.items) {
          const timeAgo = this.aiAgentService.getTimeAgo(new Date(item.timestamp));
          const sender = item.sender === 'Customer' ? 'Ø§Ù„Ø¹Ù…ÙŠÙ„' : 'Ø±Ø¯Ùƒ';
          const sanitizedContent = PromptService.sanitizeInput(item.content);
          prompt += `${item.index}. ${sender} (Ù…Ù†Ø° ${timeAgo}): ${sanitizedContent}\n`;
        }

        prompt += await PromptService.getTemplate(null, 'system_conversation_footer_global');
      } else {
        prompt += await PromptService.getTemplate(null, 'system_first_interaction');
      }
    } catch (e) {
      console.error('âŒ [RESOLVER-ERROR] HistoryResolver failed:', e.message);
      prompt += await PromptService.getTemplate(null, 'system_first_interaction'); // Safe fallback
    }

    // 5. Reply Context (Legacy logic needs refactor but keeping as is for safety)
    if (messageData?.replyContext?.isReply) {
      prompt += await PromptService.getTemplate(null, 'system_reply_context_header');
      if (messageData.replyContext.originalMessage?.content) {
        const timeAgo = this.aiAgentService.getTimeAgo(new Date(messageData.replyContext.originalMessage.createdAt));
        prompt += await PromptService.getTemplate(null, 'system_reply_context_original', {
          content: messageData.replyContext.originalMessage.content,
          timeAgo: timeAgo
        });
      } else {
        prompt += await PromptService.getTemplate(null, 'system_reply_context_unknown');
      }
      prompt += await PromptService.getTemplate(null, 'system_reply_context_footer', { customerMessage });
    }

    // 6. RAG / Products (via RagResolver)
    // ------------------------------------------------------------------
    try {
      const ragContext = RagResolver.resolve(ragData);

      if (ragContext.hasData) {
        prompt += await PromptService.getTemplate(null, 'system_rag_header');

        for (const item of ragContext.items) {
          if (item.type === 'product') {
            prompt += await PromptService.getTemplate(null, 'system_rag_product', { index: item.index, content: item.content });
          } else if (item.type === 'faq') {
            prompt += await PromptService.getTemplate(null, 'system_rag_faq', { index: item.index, content: item.content });
          } else if (item.type === 'policy') {
            prompt += await PromptService.getTemplate(null, 'system_rag_policy', { index: item.index, content: item.content });
          }
        }

        prompt += await PromptService.getTemplate(null, 'system_rag_footer');
      }

      // RAG Instructions
      if (ragContext.hasProducts) {
        prompt += await PromptService.getTemplate(null, 'system_instructions_rag');
      } else {
        // Fallback instructions handled by next block if needed
      }

    } catch (e) {
      console.error('âŒ [RESOLVER-ERROR] RagResolver failed:', e.message);
      prompt += await PromptService.getTemplate(null, 'system_instructions_no_rag');
    }

    // 7. Recent User Message
    const sanitizedMsg = PromptService.sanitizeInput(customerMessage);
    prompt += `Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„: <user_input_boundary>"${sanitizedMsg}"</user_input_boundary>\n\n`;

    // 8. ğŸ”¥ CRITICAL CONSTRAINTS (MUST BE LAST)
    prompt += await PromptService.getTemplate(null, 'critical_constraints');

    return prompt;
  }

  /**
   * Build advanced prompt with RAG data, company settings, and conversation memory
   */
  async buildAdvancedPrompt(customerMessage, customerData, companyPrompts, ragData, conversationMemory, hasImages = false, smartResponseInfo, messageData) {
    try {
      const companyId = customerData?.companyId || messageData?.companyId;
      console.log('\nğŸ”§ [BUILD-PROMPT] Ø¨Ø¯Ø¡ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ Prompt (Parallelized)');
      console.log(`ğŸ” [DEBUG-CTX] CompanyID: ${companyId}, RAG Items: ${ragData?.length || 0}`);
      if (ragData && ragData.length > 0) {
        console.log(`ğŸ” [DEBUG-CTX] First Item: ${ragData[0].type} - ${ragData[0].metadata?.name}`);
      }

      // âœ… SPEED FIX: ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ù„Ø© Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„ØªØ³Ù„Ø³Ù„
      const [
        personalityPrompt,
        shippingContext,
        historyResult,
        customerContextResult
      ] = await Promise.all([
        this._getPersonalityPrompt(companyPrompts, companyId),
        this._getShippingContext(customerMessage, companyId, conversationMemory),
        this._getConversationHistory(conversationMemory, ragData, customerMessage),
        this._getCustomerContext(customerData, conversationMemory, customerMessage)
      ]);

      let prompt = '';

      // 1. Personality & Platform Context (Parallelized)
      prompt += personalityPrompt;
      prompt += this._getPlatformContext(messageData);
      prompt += this._getResponseRules(companyPrompts);

      // 2. Post Context (Facebook Ads/Posts)
      const { prompt: postPrompt } = this._getPostContext(messageData, ragData);
      prompt += postPrompt;

      // 3. Dynamic Context Analysis (Emotional/Urgency)
      try {
        const dynamicBuilder = require('../dynamicPromptBuilder');
        const emotionalState = dynamicBuilder.detectEmotionalState(customerMessage);
        const urgencyLevel = dynamicBuilder.detectUrgencyLevel(customerMessage);
        if (emotionalState === 'frustrated' || urgencyLevel === 'high') {
          prompt += `Ù…Ù„Ø§Ø­Ø¸Ø§Øª: ${emotionalState === 'frustrated' ? 'Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…Ù†Ø²Ø¹Ø¬ - ØªØ¹Ø§Ø·ÙÙŠ | ' : ''}${urgencyLevel === 'high' ? 'Ø±Ø¯ Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø¨Ø§Ø´Ø±' : ''}\n\n`;
        }
      } catch (e) { }

      // 4. Shipping Context (Parallelized)
      prompt += shippingContext;

      // 5. Response Guidelines (Legacy support)
      if (companyPrompts?.responsePrompt) {
        prompt += `${companyPrompts.responsePrompt}\n\n`;
      }

      // 6. Customer Context (Parallelized)
      prompt += customerContextResult.prompt;

      // 7. Reply Context (if replying to a specific message)
      prompt += this._getReplyContext(messageData, customerMessage);

      // 8. Conversation History (Parallelized)
      prompt += historyResult.prompt;

      // 9. RAG / Product Context (Dependent on History/Customer Context)
      const { lastMentionedProduct } = historyResult;
      const { isNewCustomer } = customerContextResult;

      let filteredRagData = ragData;
      const msgLower = (customerMessage || '').toLowerCase();
      const isPriceQuestion = msgLower.includes('Ø³Ø¹Ø±') || msgLower.includes('Ø¨ÙƒØ§Ù…') || msgLower.includes('ÙƒØ§Ù…');

      if (isPriceQuestion && lastMentionedProduct && filteredRagData && filteredRagData.length > 0) {
        const matchingProduct = filteredRagData.find(item => {
          const pName = (item.metadata?.name || item.name || '').toLowerCase();
          return pName.includes(lastMentionedProduct.toLowerCase()) || lastMentionedProduct.toLowerCase().includes(pName);
        });
        if (matchingProduct) filteredRagData = [matchingProduct];
      }

      prompt += await this._getRAGContext(filteredRagData, smartResponseInfo, hasImages, messageData?.isPostProductResponse);

      // âœ… Force Empty RAG status if really empty to prevent hallucination
      // BUT only if the intent actually requires products (avoid scaring the bot on greetings)
      const needsProducts = ['product_inquiry', 'price_inquiry', 'shipping_inquiry', 'order_status'].includes(messageData?.intent);

      if ((!filteredRagData || filteredRagData.length === 0) && needsProducts) {
        prompt += await PromptService.getTemplate(null, 'rag_empty_strict');
      }


      // 10. Final Message Preparation
      // (Redundant Quality Instructions REMOVED - now handled by responseRulesConfig)

      // 11. The Message
      const sanitizedMsg = PromptService.sanitizeInput(customerMessage);
      prompt += `Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„: <user_input_boundary>"${sanitizedMsg}"</user_input_boundary>\n\n`;

      console.log(`âœ… [BUILD-PROMPT] Generated prompt length: ${prompt.length}`);

      // 13. ğŸ”¥ğŸ”¥ğŸ”¥ CRITICAL CONSTRAINTS (RECENCY BIAS - MUST BE LAST) ğŸ”¥ğŸ”¥ğŸ”¥
      prompt += await PromptService.getTemplate(null, 'critical_constraints');

      return prompt;

    } catch (error) {
      console.error('âŒ [BUILD-PROMPT] Error:', error);
      // Fallback to simple prompt if refactoring broke something critical
      return `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ. Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚.\nØ±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„: "${customerMessage}"\nØ±Ø¯ÙŠ Ø¨Ù„Ø·Ù ÙˆØ§Ø·Ù„Ø¨ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø³Ø¤Ø§Ù„.`;
    }
  }


  /**
   * Build order confirmation prompt
   */
  async buildOrderConfirmationPrompt(customerMessage, customerData, companyPrompts, order, orderDetails, conversationMemory, companyId) {
    try {
      console.log('ğŸ“ [ORDER-CONFIRMATION] Ø¨Ù†Ø§Ø¡ prompt Ù„ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø·Ù„Ø¨:', order.orderNumber);

      let prompt = '';

      // 1. Personality Context (Reuse helper for consistency)
      prompt += await this._getPersonalityPrompt(companyPrompts, companyId);

      // 2. Response Rules (Reuse helper for consistency)
      prompt += this._getResponseRules(companyPrompts);

      // 3. Conversation Context
      if (conversationMemory && conversationMemory.length > 0) {
        prompt += `ğŸ“š Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:\n`;
        // Use simpler slice for confirmation context
        conversationMemory.slice(-3).forEach((interaction, index) => {
          prompt += `${index + 1}. Ø§Ù„Ø¹Ù…ÙŠÙ„: ${interaction.userMessage}\n`;
          prompt += `   Ø±Ø¯Ùƒ: ${interaction.aiResponse}\n\n`;
        });
        prompt += `=====================================\n\n`;
      }

      // âœ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ø¤ÙƒØ¯ - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù€ database
      const shippingCost = order.shipping || 50;
      const totalPrice = order.total || ((orderDetails.productPrice || 0) + shippingCost);

      // âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ Ù…Ù† order.items Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©
      const orderItem = order.items && order.items.length > 0 ? order.items[0] : null;
      const productName = orderItem?.productName || orderDetails.productName || 'Ø§Ù„Ù…Ù†ØªØ¬';
      const productColor = orderItem?.productColor || orderDetails.productColor;
      const productSize = orderItem?.productSize || orderDetails.productSize;
      const productPrice = orderItem?.price || orderDetails.productPrice;

      // âœ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¯Ø© Ø§Ù„ØªÙˆØµÙŠÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      let deliveryTime = '3-5 Ø£ÙŠØ§Ù…'; // Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
      try {
        const ShippingService = require('../shippingService');
        const shippingInfo = await ShippingService.findShippingInfo(orderDetails.city, companyId);
        if (shippingInfo && shippingInfo.found && shippingInfo.deliveryTime) {
          deliveryTime = shippingInfo.deliveryTime;
          console.log(`â° [ORDER-CONFIRMATION] Ù…Ø¯Ø© Ø§Ù„ØªÙˆØµÙŠÙ„ Ù…Ù† DB: ${deliveryTime}`);
        } else {
          console.log(`âš ï¸ [ORDER-CONFIRMATION] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¯Ø© Ø§Ù„ØªÙˆØµÙŠÙ„ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©`);
        }
      } catch (error) {
        console.error(`âŒ [ORDER-CONFIRMATION] Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¯Ø© Ø§Ù„ØªÙˆØµÙŠÙ„:`, error.message);
      }

      prompt += `ğŸ‰ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ù†Ø¬Ø§Ø­!\n\n`;
      prompt += `ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ø¤ÙƒØ¯:\n`;
      prompt += `- Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨: ${order.orderNumber}\n`;
      prompt += `- Ø§Ù„Ù…Ù†ØªØ¬: ${PromptService.sanitizeInput(productName)}\n`;
      if (productColor) prompt += `- Ø§Ù„Ù„ÙˆÙ†: ${PromptService.sanitizeInput(productColor)}\n`;
      if (productSize) prompt += `- Ø§Ù„Ù…Ù‚Ø§Ø³: ${PromptService.sanitizeInput(productSize)}\n`;
      if (productPrice) prompt += `- Ø³Ø¹Ø± Ø§Ù„Ù…Ù†ØªØ¬: ${productPrice} Ø¬Ù†ÙŠÙ‡\n`;
      prompt += `- Ø§Ù„Ø´Ø­Ù†: ${shippingCost} Ø¬Ù†ÙŠÙ‡\n`;
      prompt += `- Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: ${totalPrice} Ø¬Ù†ÙŠÙ‡\n\n`;

      prompt += `ğŸ‘¤ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„:\n`;
      prompt += `- Ø§Ù„Ø§Ø³Ù…: ${PromptService.sanitizeInput(orderDetails.customerName)}\n`;
      prompt += `- Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„: ${PromptService.sanitizeInput(orderDetails.customerPhone)}\n`;
      prompt += `- Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: ${PromptService.sanitizeInput(orderDetails.customerAddress)}\n`;
      if (orderDetails.city) prompt += `- Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©: ${PromptService.sanitizeInput(orderDetails.city)}\n`;
      prompt += `\n`;

      const sanitizedMsg = PromptService.sanitizeInput(customerMessage);
      prompt += `Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®ÙŠØ±Ø©: <user_input_boundary>"${sanitizedMsg}"</user_input_boundary>\n\n`;

      // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ Ù…Ù† PromptService
      let promptTemplate = PromptService.getTemplate('order_confirmation_instructions');
      const productDetails = `${PromptService.sanitizeInput(productName)}${productColor ? ` - ${PromptService.sanitizeInput(productColor)}` : ''}${productSize ? ` - Ù…Ù‚Ø§Ø³ ${PromptService.sanitizeInput(productSize)}` : ''}`;

      prompt = PromptService.injectVariables(promptTemplate, {
        customerName: PromptService.sanitizeInput(orderDetails.customerName),
        productDetails,
        totalPrice,
        orderNumber: order.orderNumber,
        deliveryTime
      });

      return prompt;
    } catch (error) {
      console.error('âŒ [ORDER-CONFIRMATION] Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ prompt Ø§Ù„ØªØ£ÙƒÙŠØ¯:', error);
      throw error;
    }
  }



  /**
   * Generate AI response using Gemini API with Pattern Enhancement
   */
  async generateAIResponse(prompt, conversationMemory, useRAG, providedGeminiConfig, companyId, conversationId, messageContext) {
    const startTime = Date.now();
    let lastError = null;
    let attempts = 0;

    // âœ… FIX: ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ø¶Ù…Ø§Ù† ØªØ¬Ø±Ø¨Ø© Ø§Ù„ÙƒÙ„
    const totalAvailableKeys = await this.aiAgentService.getModelManager().getTotalKeysCount(companyId);
    const MAX_KEY_RETRIES = Math.max(totalAvailableKeys, 3);

    console.log(`ğŸš€ [AI-RESPONSE] Starting generation with up to ${MAX_KEY_RETRIES} dynamic retries (Total keys: ${totalAvailableKeys})`);

    // âœ… FIX 1: Ø¥Ù†Ø´Ø§Ø¡ session ID Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¬Ø±Ø¨Ø©
    const sessionId = `${companyId}_${conversationId}_${Date.now()}`;

    // âœ… ØªØªØ¨Ø¹ Ø§Ø³Ù… Ø¢Ø®Ø± Ù…ÙØªØ§Ø­ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ (Scope Fix)
    let lastUsedKeyName = null;

    // âœ… SPEED FIX: ØªØªØ¨Ø¹ ÙØ´Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø§Ù„Ø³Ø±ÙŠØ¹ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ§Ù„ÙŠ
    const modelFailureCount = new Map(); // modelName -> failCount
    const MAX_FAILURES_PER_MODEL = 3; // Ø¨Ø¹Ø¯ 3 ÙØ´Ù„ØŒ Ø§Ù†ØªÙ‚Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ§Ù„ÙŠ
    const exhaustedModelsInSession = new Set(); // Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø³ØªÙ†ÙØ¯Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù„Ø³Ø©

    // âœ… CACHE CHECK: Semantic Caching (Layer 1)
    try {
      // Don't use cache if specific config provided (force refresh context)
      if (!providedGeminiConfig) {
        const cachedResponse = await semanticCacheService.getCachedResponse(prompt, companyId);
        if (cachedResponse) {
          console.log(`ğŸ§  [CACHE-HIT] Serving response from semantic cache`);
          return {
            content: cachedResponse,
            keyName: 'CACHE',
            model: 'SEMANTIC-CACHE',
            provider: 'CACHE',
            processingTime: 0,
            cached: true
          };
        }
      }
    } catch (cacheErr) {
      console.warn('âš ï¸ [CACHE-CHECK] Failed:', cacheErr.message);
    }

    try {
      // âœ… Ø¨Ø¯Ø§ÙŠØ© Ø­Ù„Ù‚Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­
      while (attempts < MAX_KEY_RETRIES) {
        attempts++;
        console.log(`ğŸ”„ [AI-RESPONSE] Attempt ${attempts}/${MAX_KEY_RETRIES} to generate response...`);

        // âœ… FIX: Ø¥Ø¹Ù„Ø§Ù† geminiConfig Ù‡Ù†Ø§ Ù„ÙŠÙƒÙˆÙ† Ù…Ø­Ù„ÙŠØ§Ù‹ Ù„ÙƒÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
        let geminiConfig = null;

        try {
          console.log(`ğŸ” [AI-RESPONSE] Ø¨Ø¯Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø´Ø±ÙƒØ© ${companyId}, Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ${conversationId} - Session: ${sessionId}`);

          // ğŸ”¥ [HARDENING] ØªÙ‚Ø¯ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù‚Ø¨Ù„ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙØªØ§Ø­ Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ 429 TPM
          const predictedTokens = this.aiAgentService.getModelManager().estimateTokenCount(prompt);
          console.log(`ğŸ§  [TOKEN-PREDICTION] Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ÙŠ: ${predictedTokens} (Prompt Length: ${prompt.length})`);

          // Get active Gemini configuration
          // âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Reactive Round-Robin Ø¯Ø§Ø¦Ù…Ø§Ù‹ (Ø¨Ø¯ÙˆÙ† Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒÙˆØªØ©)
          const modelSelectionStart = Date.now();

          if (!providedGeminiConfig || attempts > 1) {
            // âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Reactive Round-Robin
            geminiConfig = await this.aiAgentService.getModelManager().getNextKeySimple(companyId);
          } else {
            geminiConfig = providedGeminiConfig;
          }

          const modelSelectionDuration = Date.now() - modelSelectionStart;

          // âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ø¹Ø·Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹
          if (geminiConfig && geminiConfig.error === 'ALL_KEYS_UNAVAILABLE') {
            console.error(`âŒ [AI-RESPONSE] Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ø¹Ø·Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„Ù„Ø´Ø±ÙƒØ© ${companyId}`);
            const error = new Error(geminiConfig.message || 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ø¹Ø·Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹.');
            error.code = 'ALL_KEYS_UNAVAILABLE';
            error.arabicMessage = geminiConfig.message || 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ø¹Ø·Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø£Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¯Ø¹Ù….';
            error.retryAfter = geminiConfig.retryAfter || 30;
            throw error;
          }

          if (!geminiConfig) {
            console.error(`âŒ [AI-RESPONSE] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ù†Ø´Ø· Ù„Ù„Ø´Ø±ÙƒØ© ${companyId} (Attempts: ${attempts})`);

            // âœ… FAST ROTATION: If we have attempts left, rotate faster
            if (attempts < MAX_KEY_RETRIES) {
              const totalKeysCount = await this.aiAgentService.getModelManager().getTotalKeysCount(companyId);
              // If we have other keys available, use a very short backoff (500ms)
              const waitTime = (attempts < totalKeysCount) ? 500 : this.getBackoffDelay(attempts - 1);

              console.log(`â³ [FAST-ROTATION] Waiting ${waitTime}ms before retry ${attempts + 1} (Keys available: ${totalKeysCount})...`);
              await new Promise(resolve => setTimeout(resolve, waitTime));
              continue;
            }
            throw new Error(`No active Gemini key found for company: ${companyId}`);
          }

          console.log(`âœ… [AI-RESPONSE] ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: ${geminiConfig.model} (Key: ${geminiConfig.keyName || geminiConfig.keyId}) - ÙˆÙ‚Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±: ${modelSelectionDuration}ms`);

          // âœ… ØªØ­Ø¯ÙŠØ« Ø§Ø³Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
          lastUsedKeyName = geminiConfig.keyName || geminiConfig.keyId;

          // Step 1: Use prompt directly (pattern enhancement removed)
          let enhancedPrompt = prompt;

          // âœ¨ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
          const generationConfig = await this.buildGenerationConfig(companyId, messageContext);

          // âœ… PHASE 3: Semantic Cache Check
          // Only cache 'general' or 'inquiry' messages to avoid caching sensitive order data
          const shouldCache = !messageContext?.messageType || ['general', 'inquiry'].includes(messageContext.messageType);

          if (shouldCache) {
            const cachedResponse = await semanticCacheService.getCachedResponse(enhancedPrompt, companyId, geminiConfig.model);
            if (cachedResponse) {
              console.log('âš¡ [RESPONSE-GENERATOR] Returning Cached Response');
              return {
                content: cachedResponse.content,
                model: cachedResponse.model,
                provider: 'CACHE',
                processingTime: 0,
                cached: true
              };
            }
          }

          // Step 2: Generate AI response
          console.log(`ğŸ“¡ [AI-PROVIDER] Using factory for provider: ${geminiConfig.provider || 'GOOGLE'}`);
          const provider = AIProviderFactory.getProvider(geminiConfig.provider || 'GOOGLE', geminiConfig.apiKey, geminiConfig.baseUrl, geminiConfig.keyId);

          const result = await provider.generateResponse(enhancedPrompt, {
            model: geminiConfig.model,
            ...generationConfig
          });

          // âœ… FIX: Handle both function and string text formats FIRST
          const getText = () => {
            if (typeof result.text === 'function') {
              return result.text();
            } else if (typeof result.text === 'string') {
              return result.text;
            } else if (result.content) {
              return result.content;
            } else {
              return '';
            }
          };

          const response = {
            text: getText,
            usageMetadata: result.usageMetadata,
            candidates: result.candidates,
            promptFeedback: result.promptFeedback
          };


          // ... (Validation Logic from previous code - MAX_TOKENS, Blocked, etc.) ...
          // IMPORTANT: If validation fails with a "Silent Reason", we should Return immediately OR Continue?
          // Usually blocked content means the PROMPT is bad, not the key. so we Return.

          // ... [Insert Validation Logic Here - abbreviated for brevity since it's inside success path] ...
          // For the purpose of replace_file_content, I need to include the critical validation check.

          // Check block reason
          if (response.promptFeedback?.blockReason) {
            // ... handle block ...
            return { content: null, silentReason: `ØªÙ… Ø­Ø¸Ø± Ø§Ù„Ø±Ø¯ Ø¨Ø³Ø¨Ø¨: ${response.promptFeedback.blockReason}` };
          }

          // Extract content
          let aiContent = '';
          if (response.candidates && response.candidates.length > 0) {
            const candidate = response.candidates[0];
            if (candidate.finishReason === 'SAFETY' || candidate.finishReason === 'RECITATION') {
              return { content: null, silentReason: `ØªÙ… Ø­Ø¸Ø± Ø§Ù„Ø±Ø¯ Ø¨Ø³Ø¨Ø¨: ${candidate.finishReason}` };
            }
            if (candidate.content?.parts) {
              aiContent = candidate.content.parts.map(p => p.text).join('');
            } else {
              // âœ… FIX: Use getText() which handles both function and string
              aiContent = getText();
            }
          } else {
            // âœ… FIX: Use getText() which handles both function and string
            aiContent = getText(); // Fallback
          }

          // âœ… If we got here, we have success!
          // Record usage
          const usedModelId = geminiConfig.modelId;
          let totalTokens = response.usageMetadata?.totalTokenCount || 0;
          if (usedModelId) {
            await this.aiAgentService.updateModelUsage(usedModelId, totalTokens);
          }

          const trimmedContent = aiContent ? aiContent.trim() : '';

          // âœ… FIX: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† aiConstants Ù…Ø¹ fallback
          const MIN_LENGTH = RESPONSE_VALIDATION?.MIN_LENGTH || 2;

          // Simple length check
          if (trimmedContent.length < MIN_LENGTH) {
            // âœ… Log the actual response for debugging
            console.warn(`âš ï¸ [SHORT-RESPONSE] Response too short: length=${trimmedContent.length}, content="${trimmedContent.substring(0, 50)}", model=${geminiConfig.model}, key=${geminiConfig.keyName || geminiConfig.keyId}`);

            // âœ… REPORT FAILURE: Ø§Ø³ØªØ®Ø¯Ø§Ù… SimpleKeyRotator Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…Ø¤Ù‚Øª
            if (geminiConfig?.keyId) {
              console.log(`ğŸ”Œ [SHORT-RESPONSE] Reporting glitch for key ${geminiConfig.keyId} to force rotation...`);
              await this.aiAgentService.getModelManager().markKeyFailed(
                geminiConfig.keyId,
                'RESPONSE_TOO_SHORT',
                5000 // 5 seconds cooldown to skip this key in the next attempt
              );
            }

            // Signal retry
            throw new Error('Response too short or empty');
          }



          // Log Success
          const totalDuration = Date.now() - startTime;
          console.log(`âœ… [AI-RESPONSE] Success in attempt ${attempts} - Duration: ${totalDuration}ms`);
          console.log(`âœ… [AI-RESPONSE] Success in attempt ${attempts} - Duration: ${totalDuration}ms`);



          // âœ… LOGGING: Async via Queue (Fire-and-Forget)
          try {
            const logPayload = {
              companyId,
              customerId: messageContext?.customerId || conversationMemory?.customerId || null,
              modelUsed: geminiConfig.model,
              keyId: geminiConfig.keyId,
              keyName: geminiConfig.keyName,
              userMessage: prompt.substring(0, 5000) || '',
              aiResponse: aiContent ? aiContent.substring(0, 5000) : '',
              tokensUsed: totalTokens || 0,
              responseTime: totalDuration,
              metadata: JSON.stringify({
                conversationId,
                attempts,
                sessionId
              })
            };

            await queueService.add('ai-logs', 'logInteraction', logPayload);
            console.log('âœ… [AI-LOG] Queued interaction log successfully');
          } catch (logError) {
            console.error('âŒ [AI-LOG] Failed to queue log:', logError);
          }

          // âœ… CACHE SAVE: Semantic Caching (Layer 1)
          // Only cache if content is valid and long enough
          if (aiContent && aiContent.length > 10 && !providedGeminiConfig) {
            try {
              await semanticCacheService.cacheResponse(prompt, aiContent, companyId, geminiConfig.model);
            } catch (cacheSaveErr) {
              console.warn('âš ï¸ [CACHE-SAVE] Failed:', cacheSaveErr.message);
            }
          }


          // âœ… FIX: Return object with metadata instead of just string
          return {
            content: aiContent.trim(),
            keyName: geminiConfig.keyName || geminiConfig.keyId,
            model: geminiConfig.model,
            provider: geminiConfig.provider, // âœ… NEW
            processingTime: totalDuration
          };

        } catch (attemptError) {
          console.warn(`âš ï¸ [AI-RESPONSE] Attempt ${attempts} failed: ${attemptError.message}`);
          lastError = attemptError; // Save for final throw

          const is429 = attemptError.status === 429 || attemptError.message?.includes('429') || attemptError.message?.includes('quota');
          const is503 = attemptError.status === 503 || attemptError.message?.includes('503');
          const is404 = attemptError.status === 404 || attemptError.message?.includes('not found') || attemptError.message?.includes('404');

          // âœ… FIX: ØªØ­Ø³ÙŠÙ† Ø§ÙƒØªØ´Ø§Ù Ø£Ø®Ø·Ø§Ø¡ 403 ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…Ø³Ø±Ø¨Ø©
          const errorMessage = (attemptError.message || '').toLowerCase();
          const isLeakedKey = errorMessage.includes('leaked') || errorMessage.includes('reported as leaked');
          const isInvalidKey = errorMessage.includes('key not valid') || errorMessage.includes('invalid api key') || errorMessage.includes('api key was reported');
          const is403 = attemptError.status === 403 || isInvalidKey || isLeakedKey || errorMessage.includes('403') || errorMessage.includes('forbidden');

          // âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù‚Ø§ØªÙ„Ø© (Circuit Breaker)
          if (is403 && geminiConfig?.keyId) {
            const reason = isLeakedKey ? 'LEAKED' : '403_INVALID';
            console.error(`ğŸ›‘ [CRITICAL] Invalid/Leaked Key detected (${geminiConfig.keyId}). Reason: ${reason}. Invalidating...`);

            // âœ… NEW: Ø§Ø³ØªØ®Ø¯Ø§Ù… Simple Rotator Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…Ø¤Ù‚Øª
            await this.aiAgentService.getModelManager().markKeyFailed(geminiConfig.keyId, reason);

            // Ø¥Ø¨Ø·Ø§Ù„ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            await this.aiAgentService.getModelManager().invalidateKey(geminiConfig.keyId, reason);
            continue; // Try next key
          }

          if (is404 && geminiConfig?.modelId) {
            console.error(`ğŸ›‘ [CRITICAL] Model Not Found (${geminiConfig.model}). Disabling...`);
            await this.aiAgentService.getModelManager().disableModel(geminiConfig.modelId, '404_NOT_FOUND');
            continue; // Try next key/model
          }

          // âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙƒÙˆØªØ§/Ø§Ù„Ø´Ø¨ÙƒØ© Ù„Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø­Ø§Ù„ÙŠ
          if (geminiConfig?.model && (is429 || is503)) {
            const currentModel = geminiConfig.model;

            console.warn(`âš ï¸ [KEY-ROTATION] Model ${currentModel} failed (Attempt ${attempts}/${MAX_KEY_RETRIES}) - marking as exhausted`);

            // âœ… RETRY-AFTER: Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù…Ù† Ø§Ù„Ø±Ø£Ø³ Ø£Ùˆ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            let retryAfterMs = null;
            if (attemptError.response?.headers?.get('retry-after')) {
              const retryHeader = attemptError.response.headers.get('retry-after');
              if (!isNaN(retryHeader)) {
                retryAfterMs = parseInt(retryHeader, 10) * 1000;
              } else {
                retryAfterMs = new Date(retryHeader).getTime() - Date.now();
              }
            }
            if (!retryAfterMs) {
              const match = errorMessage.match(/retry in (\d+(\.\d+)?)s/);
              if (match) retryAfterMs = parseFloat(match[1]) * 1000;
            }

            // âœ… REPORT FAILURE: Ø§Ø³ØªØ®Ø¯Ø§Ù… Simple Rotator Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…Ø¤Ù‚Øª
            await this.aiAgentService.getModelManager().markKeyFailed(geminiConfig.keyId, '429', retryAfterMs);

            // âœ… FAST ROTATION: If we have multiple keys, switch fast
            const totalKeys = await this.aiAgentService.getModelManager().getTotalKeysCount(companyId);
            const waitTime = (attempts < totalKeys) ? 500 : this.getBackoffDelay(attempts);

            console.log(`â³ [FAST-ROTATION] Rotation delay: ${waitTime}ms (Attempt ${attempts}/${totalKeys} keys)`);
            await new Promise(resolve => setTimeout(resolve, waitTime));
            continue;
          }

          // If it's a different error (e.g. 400 Bad Request), it might be prompt related.
          // Getting a new key won't fix a bad prompt.
          // However, sometimes it's "Internal Error" which switching might fix.
          if (attemptError.status >= 500) {
            // ğŸ”„ Ø¥Ø¶Ø§ÙØ© ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ· Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            await new Promise(resolve => setTimeout(resolve, 250));
            continue; // Retry for server errors
          }

          // âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø­Ø¸ÙˆØ± (Safety) - Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù„Ø£Ù† Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø·Ù„Ø¨ Ù†ÙØ³Ù‡
          const isSafety = errorMessage.includes('safety') || errorMessage.includes('blocked');
          if (isSafety) {
            console.warn(`ğŸ›‘ [AI-SAFE] Content blocked by safety filters. Breaking loop.`);
            return { content: null, silentReason: `ØªÙ… Ø­Ø¸Ø± Ø§Ù„Ø±Ø¯ Ù„Ø£Ø³Ø¨Ø§Ø¨ ØªØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ø³Ù„Ø§Ù…Ø© (Safety Block)` };
          }

          // âœ… FIX: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ - Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Ù…ÙØªØ§Ø­/Ù†Ù…ÙˆØ°Ø¬ Ø¢Ø®Ø±
          const isTooShort = errorMessage.includes('response too short') || errorMessage.includes('too short or empty') || errorMessage.includes('too short');
          if (isTooShort && geminiConfig?.model) {
            console.warn(`âš ï¸ [SHORT-RESPONSE] Attempt ${attempts}: Model ${geminiConfig.model} (Key: ${geminiConfig.keyName || geminiConfig.keyId}) returned empty/short response - retrying with next key/model (${attempts}/${MAX_KEY_RETRIES})`);
            // ğŸ”„ Ø¥Ø¶Ø§ÙØ© ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ· Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            await new Promise(resolve => setTimeout(resolve, 100));
            continue; // Retry with next key/model
          }

          // For 400s (Invalid Argument), break loop to avoid burning keys on bad requests
          break;
        }
      } // End while loop

      // âŒ If we exit loop without returning, all attempts failed
      throw lastError || new Error(`Failed to generate response after ${MAX_KEY_RETRIES} attempts`);

    } catch (error) {
      // ... (Original outer catch block for silent logging) ...
      const totalDuration = Date.now() - startTime;
      console.error(`âŒ [AI-RESPONSE] All attempts failed - Total time: ${totalDuration}ms - Error: ${error.message}`);
      console.error(`âŒ [AI-RESPONSE] Error details:`, {
        message: error.message,
        stack: error.stack?.split('\n').slice(0, 5).join('\n'),
        attempts: attempts,
        totalDuration: totalDuration,
        lastUsedKeyName: lastUsedKeyName,
        companyId: companyId,
        conversationId: conversationId
      });

      // âœ… ASYNC FAILURE LOGGING
      try {
        const failurePayload = {
          companyId,
          conversationId,
          customerId: messageContext?.customerId || null,
          errorType: error.code || 'UNKNOWN_ERROR',
          errorMessage: error.message,
          context: JSON.stringify({
            attempts,
            lastModel: lastUsedKeyName,
            duration: totalDuration
          })
        };
        await queueService.add('ai-logs', 'logFailure', failurePayload);
      } catch (e) {
        console.warn('âš ï¸ Failed to queue failure log');
      }

      // âœ… DEBUG: Save prompt to file for debugging silent errors
      try {
        const fs = require('fs');
        const debugInfo = `Time: ${new Date().toISOString()}\nError: ${error.message}\nKey: ${lastUsedKeyName}\nPrompt Length: ${prompt?.length || 0}\n\nPROMPT:\n${prompt}`;
        fs.writeFileSync('last_silent_prompt.txt', debugInfo, 'utf8');
      } catch (e) { }

      // ğŸ¤ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØµØ§Ù…Øª - ØªØ³Ø¬ÙŠÙ„ ÙˆØªØµÙ†ÙŠÙ
      // ... (Existing silent handling code) ...



      // âœ… ØªØµÙ†ÙŠÙ Ù…ÙˆØ­Ø¯ Ù„Ù„Ø®Ø·Ø£ Ø§Ù„ØµØ§Ù…Øª
      let silentReason = `Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯: ${error.message}`;
      if (lastUsedKeyName) {
        silentReason += ` (Key: ${lastUsedKeyName})`;
      }

      // âŒ REMOVED: Timeout check - ØªÙ… Ø¥Ø²Ø§Ù„ØªÙ‡ Ø­Ø³Ø¨ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
      // if (totalDuration > 30000) {
      //   silentReason += ` - ØªØ¬Ø§ÙˆØ² Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ (${Math.round(totalDuration / 1000)}s)`;
      // }

      // âœ… FIX: ØªØµÙÙŠØ© Ø®Ø·Ø£ MISSING_PERSONALITY_PROMPT Ù„Ø£Ù†Ù‡ ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
      const errorMsgLower = (error.message || '').toLowerCase();
      if (error.message?.includes('MISSING_PERSONALITY_PROMPT')) {
        console.warn('âš ï¸ [AI-RESPONSE] MISSING_PERSONALITY_PROMPT error detected - this should not happen as default personality is used');
        silentReason = 'Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ - ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰';
      } else if (error.message?.includes('quota') || error.message?.includes('429') || error.message?.includes('ÙƒÙˆØªØ§') || error.code === 'QUOTA_EXHAUSTED' || error.code === 'ALL_KEYS_UNAVAILABLE') {
        silentReason = error.arabicMessage || 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ø¹Ø·Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹ - ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹';
      } else if (errorMsgLower.includes('response too short') || errorMsgLower.includes('too short or empty') || errorMsgLower.includes('too short')) {
        // âœ… FIX: ØªØ­Ø³ÙŠÙ† Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ù„Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù‚ØµÙŠØ±Ø©
        silentReason = 'ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ù…Ù†Ø§Ø³Ø¨ - ØªÙ… ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ØªØ§Ø­Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ø§Ù‹';
        if (lastUsedKeyName) {
          silentReason += ` (Ø¢Ø®Ø± Ù…ÙØªØ§Ø­ Ø¬Ø±Ø¨: ${lastUsedKeyName})`;
        }
      }
      // âŒ REMOVED: Timeout handling - ØªÙ… Ø¥Ø²Ø§Ù„ØªÙ‡ Ø­Ø³Ø¨ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
      // else if (error.code === 'TIMEOUT' || errorMsgLower.includes('timeout') || totalDuration > 30000) {
      //   silentReason = `Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± - Ø§Ø³ØªØºØ±Ù‚ Ø§Ù„Ø·Ù„Ø¨ ${Math.round(totalDuration / 1000)} Ø«Ø§Ù†ÙŠØ©`;
      //   if (lastUsedKeyName) {
      //     silentReason += ` (Key: ${lastUsedKeyName})`;
      //   }
      // }

      return { content: null, silentReason: silentReason, processingTime: totalDuration };
    }
  }


  /**
        prompt += `Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© (Ù…Ù†ØªØ¬Ø§Øª/Ø³ÙŠØ§Ø³Ø§Øª):\n`;
        ragData.slice(0, 3).forEach(item => {
          prompt += `- ${item.content.substring(0, 100)}...\n`;
        });
        prompt += `\n`;
      }

      // Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØµØ§Ø±Ù…Ø©
      prompt += `Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:\n`;
      prompt += `1. Ø§Ù‚ØªØ±Ø­ÙŠ 3 Ø±Ø¯ÙˆØ¯ Ù…Ø®ØªÙ„ÙØ© (Ù‚ØµÙŠØ±Ø©ØŒ Ù…ØªÙˆØ³Ø·Ø©ØŒ ÙˆÙ…ÙØµÙ„Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹).\n`;
      prompt += `2. ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆØ§Ù„ÙˆØ¯ÙˆØ¯Ø© (Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø´Ø®ØµÙŠØ© ØªÙØ±Ø¶ ØºÙŠØ± Ø°Ù„Ùƒ).\n`;
      prompt += `3. Ø§Ù„Ø±Ø¯ÙˆØ¯ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø¥Ø±Ø³Ø§Ù„ ÙÙˆØ±Ø§Ù‹ (Ù„Ø§ ØªØ¶Ø¹ÙŠ Ø£Ù‚ÙˆØ§Ø³ Ø£Ùˆ Ø´Ø±Ø­).\n`;
      prompt += `4. Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù…ØµÙÙˆÙØ© JSON Ù†ØµÙŠØ© ÙÙ‚Ø· (Array of strings).\n`;
      prompt += `5. Ù„Ø§ ØªÙƒØªØ¨ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ Ø®Ø§Ø±Ø¬ Ù…ØµÙÙˆÙØ© JSON.\n`;
      prompt += `6. Ù…Ø«Ø§Ù„ Ù„Ù„Ù…Ø®Ø±Ø¬Ø§Øª: ["Ø£Ù‡Ù„Ø§Ù‹ ÙŠØ§ ÙÙ†Ø¯Ù…ØŒ Ø¥Ø²Ø§ÙŠ Ø£Ù‚Ø¯Ø± Ø§Ø³Ø§Ø¹Ø¯ÙƒØŸ", "Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ Ù‡ÙŠ 41 Ùˆ 42", "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†ØªØ¬ 500 Ø¬Ù†ÙŠÙ‡ ÙˆØ§Ù„ØªÙˆØµÙŠÙ„ Ù…Ø¬Ø§Ù†ÙŠ"]\n\n`;
      prompt += `Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (JSON Array Only):`;

      // 2. Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (using existing methods)
      // Ù†Ø³ØªØ®Ø¯Ù… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø§ÙØ¸Ø© (Low Temperature) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ JSON Ø¯Ù‚ÙŠÙ‚
      const generationConfig = {
        temperature: 0.3,
        maxOutputTokens: 500,
        responseMimeType: "application/json" // Gemini 1.5 supports this
      };

      const modelManager = this.aiAgentService.getModelManager();
      const activeKey = await modelManager.getActiveAIKeyWithModel(companyId);

      // âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ÙØªØ§Ø­
      if (!activeKey || activeKey.error) {
        const error = activeKey?.error === 'ALL_KEYS_UNAVAILABLE' || activeKey?.error === 'QUOTA_EXHAUSTED'
          ? new Error(activeKey.message || activeKey.arabicMessage || 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ø¹Ø·Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹.')
          : new Error('No active Gemini key found');
        if (activeKey?.error === 'ALL_KEYS_UNAVAILABLE' || activeKey?.error === 'QUOTA_EXHAUSTED') {
          error.code = activeKey.error;
          error.arabicMessage = activeKey.message || activeKey.arabicMessage;
          error.retryAfter = activeKey.retryAfter;
        }
        throw error;
      }

      const provider = AIProviderFactory.getProvider(activeKey.provider || 'GOOGLE', activeKey.apiKey || activeKey.key, activeKey.baseUrl, activeKey.id);
      const result = await provider.generateResponse(prompt, {
        model: activeKey.model || "gemini-1.5-flash",
        ...generationConfig
      });
      // âœ… FIX: Handle both function and string text formats
      const responseText = typeof result.text === 'function' ? result.text() : (result.text || result.content || '');

      // 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ©
      let suggestions = [];
      try {
        // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø¹Ù„Ø§Ù…Ø§Øª markdown Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
        const cleanText = responseText.replace(/```json/g, '').replace(/```/g, '').trim();
        suggestions = JSON.parse(cleanText);
      } catch (parseError) {
        console.warn('âš ï¸ [AI-SUGGESTIONS] Failed to parse JSON, trying regex fallback', responseText);
        // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø¨ÙŠÙ† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ†ØµÙŠØµ ÙƒØ­Ù„ Ø¨Ø¯ÙŠÙ„
        const matches = responseText.match(/"([^"]*)"/g);
        if (matches) {
          suggestions = matches.map(s => s.replace(/"/g, ''));
        } else {
          // Fallback final: return raw lines
          suggestions = responseText.split('\n').filter(line => line.length > 5).slice(0, 3);
        }
      }

      // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ù…ØµÙÙˆÙØ©
      if (!Array.isArray(suggestions)) {
        suggestions = [typeof suggestions === 'string' ? suggestions : "Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙƒØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ"];
      }

      return suggestions.slice(0, 3); // Ø¶Ù…Ø§Ù† Ø¥Ø±Ø¬Ø¹ 3 Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰

    } catch (error) {
      console.error('âŒ [AI-SUGGESTIONS] Error generating suggestions:', error);
      // Fallback suggestions
      return [
        "Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙƒØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ",
        "ØªÙØ¶Ù„ØŒ Ø£Ù†Ø§ Ù…Ø¹Ø§Ùƒ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±Ø§ØªÙƒ.",
        "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø£Ø®Ø±Ù‰ØŸ"
      ];
    }
  }
  /**
   * ğŸ”’ Helper: Get Personality Prompt
   */
  async _getPersonalityPrompt(companyPrompts, companyId) {
    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ personality prompt ØµØ§Ù„Ø­ (Ù„ÙŠØ³ ÙØ§Ø±Øº ÙˆÙ„ÙŠØ³ placeholder)
    const personalityPromptTrimmed = companyPrompts?.personalityPrompt?.trim() || '';
    const isPlaceholder = personalityPromptTrimmed.startsWith('# ÙŠØ¬Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯ Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ') ||
      personalityPromptTrimmed.startsWith('#ÙŠØ¬Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯ Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ') ||
      personalityPromptTrimmed.includes('ÙŠØ¬Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯ Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ù…Ù† Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…') ||
      personalityPromptTrimmed.startsWith('ÙŠØ¬Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯ Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ');

    if (!companyPrompts || !personalityPromptTrimmed || isPlaceholder) {
      // Ø¥Ù†Ø´Ø§Ø¡ companyPrompts Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
      if (!companyPrompts) companyPrompts = {};

      // Ø§Ø³ØªØ®Ø¯Ø§Ù… personality Ø§ÙØªØ±Ø§Ø¶ÙŠ
      companyPrompts.personalityPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…Ø­ØªØ±Ù ÙˆÙˆØ¯ÙˆØ¯ Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡.
ØªØªØ­Ø¯Ø« Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙ…Ø­ØªØ±Ù… Ù…Ø¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±Ø§ØªÙ‡Ù… ÙˆØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©.
ØªÙƒÙˆÙ† Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙ…Ù‡Ø°Ø¨Ø§Ù‹ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„Ø§Øª.`;

      companyPrompts.source = 'default_fallback';
      companyPrompts.hasCustomPrompts = false;
    }

    return `${companyPrompts.personalityPrompt.trim()}\n\n`;
  }

  /**
   * ğŸ”’ Helper: Get Platform Context
   */
  _getPlatformContext(messageData) {
    const platform = messageData?.platform;
    let context = '';

    if (platform === 'test-chat') {
      context += `ğŸ“± Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©: Ø£Ù†Øª ØªØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ø¨Ø± Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ (Test Chat).
- Ù‡Ø°Ù‡ Ø¯Ø±Ø¯Ø´Ø© ÙÙˆØ±ÙŠØ© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©
- ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø©
- Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠÙ†ØªØ¸Ø± Ø±Ø¯Ùƒ Ø§Ù„Ø¢Ù†
- ÙƒÙ† Ø³Ø±ÙŠØ¹Ø§Ù‹ ÙˆÙ…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙÙŠ Ø§Ù„Ø±Ø¯\n\n`;
    } else if (platform === 'whatsapp') {
      context += `ğŸ“± Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©: Ø£Ù†Øª ØªØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ø¨Ø± ÙˆØ§ØªØ³Ø§Ø¨.\n\n`;
    } else if (platform === 'facebook') {
      context += `ğŸ“± Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©: Ø£Ù†Øª ØªØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ø¨Ø± ÙÙŠØ³Ø¨ÙˆÙƒ Ù…Ø§Ø³Ù†Ø¬Ø±.\n\n`;
    }
    return context;
  }

  /**
   * ğŸ”’ Helper: Get Response Rules
   */
  _getResponseRules(companyPrompts) {
    let prompt = '';
    if (companyPrompts.responseRules) {
      try {
        const rules = typeof companyPrompts.responseRules === 'string'
          ? JSON.parse(companyPrompts.responseRules)
          : companyPrompts.responseRules;
        prompt += buildPromptFromRules(rules);
      } catch (e) {
        console.warn('âš ï¸ [RESPONSE-RULES] Failed to parse responseRules:', e.message);
        prompt += buildPromptFromRules(getDefaultRules());
      }
    } else {
      prompt += buildPromptFromRules(getDefaultRules());
    }
    return prompt;
  }

  /**
   * ğŸ”’ Helper: Get Post Context
   */
  _getPostContext(messageData, ragData) {
    let prompt = '';
    let postProductInfo = null;

    // 1. Check for Post Product Info (from RAG based on context)
    if (messageData?.isPostProductResponse && ragData && ragData.length > 0) {
      const product = ragData[0];
      const productName = product.metadata?.name || product.name || 'Ø§Ù„Ù…Ù†ØªØ¬';
      const productPrice = product.metadata?.price || product.price || 'ØºÙŠØ± Ù…ØªÙˆÙØ±';

      postProductInfo = { name: productName, price: productPrice };

      prompt += `Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¬Ø§Ø¡ Ù…Ù† Ø¨ÙˆØ³Øª Facebook:\n`;
      prompt += `- Ø§Ù„Ù…Ù†ØªØ¬: ${postProductInfo.name} - ${postProductInfo.price} Ø¬Ù†ÙŠÙ‡\n`;
      prompt += `- Ø§Ø°ÙƒØ±ÙŠ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ø³Ø¹Ø± Ø¨ÙˆØ¶ÙˆØ­ Ø¹Ù†Ø¯ Ø§Ù„Ø³Ø¤Ø§Ù„\n\n`;
    }

    // 2. Check for original Post Details (from Webhook)
    if (messageData?.postDetails) {
      const postDetails = messageData.postDetails;
      prompt += `ğŸ“Œ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø§Ù„Ø°ÙŠ Ø¬Ø§Ø¡ Ù…Ù†Ù‡ Ø§Ù„Ø¹Ù…ÙŠÙ„:\n`;
      prompt += `=====================================\n`;

      if (postDetails.message) {
        const sanitizedPostMsg = PromptService.sanitizeInput(postDetails.message);
        prompt += `ğŸ“ Ù†Øµ Ø§Ù„Ù…Ù†Ø´ÙˆØ±:\n"${sanitizedPostMsg}"\n\n`;
      }

      if (postDetails.hasImages && postDetails.imageUrls?.length > 0) {
        prompt += `ğŸ–¼ï¸ Ø§Ù„Ù…Ù†Ø´ÙˆØ± ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ${postDetails.imageUrls.length} ØµÙˆØ±Ø©\n`;
        prompt += `ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù…ÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„ÙÙ‡Ù… Ø§Ù„Ù…Ù†ØªØ¬/Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙŠ ÙŠØ³Ø£Ù„ Ø¹Ù†Ù‡Ø§ Ø§Ù„Ø¹Ù…ÙŠÙ„\n\n`;
      }

      prompt += `ğŸ’¡ Ù…Ù‡Ù…: Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¬Ø§Ø¡ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†Ø´ÙˆØ± - Ø§Ø³ØªØ®Ø¯Ù…ÙŠ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ù„ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚\n`;
      if (!postProductInfo) {
        prompt += `ğŸ’¡ Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø± Ø£Ùˆ Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø¯ÙˆÙ† ØªØ­Ø¯ÙŠØ¯ØŒ ÙØ§Ù„Ù…Ù‚ØµÙˆØ¯ Ù‡Ùˆ Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ø°ÙƒÙˆØ± ÙÙŠ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø£Ø¹Ù„Ø§Ù‡\n`;
      }
      prompt += `=====================================\n\n`;
    }

    return { prompt, postProductInfo };
  }


  // âœ… Re-implemented Helpers using Phase 3 Resolvers

  /**
   * ğŸ”’ Helper: Get Shipping Context
   */
  async _getShippingContext(customerMessage, companyId, conversationMemory) {
    try {
      const shippingData = await ShippingResolver.resolve(customerMessage, companyId, conversationMemory);
      let prompt = '';
      if (shippingData && shippingData.shippingInfo) {
        prompt += await PromptService.getTemplate(companyId, 'shipping_response', shippingData.shippingInfo);
      } else if (shippingData && shippingData.isAsking && shippingData.foundGovernorate && !shippingData.shippingInfo) {
        prompt += await PromptService.getTemplate(companyId, 'no_shipping_found', { governorate: shippingData.foundGovernorate });
      } else if (shippingData && shippingData.isAsking) {
        prompt += await PromptService.getTemplate(null, 'system_shipping_alert', { customerMessage });
      }
      return prompt;
    } catch (error) {
      console.warn('âš ï¸ [_getShippingContext] Error:', error.message);
      return '';
    }
  }

  /**
   * ğŸ”’ Helper: Get Customer Context
   */
  _getCustomerContext(customerData, conversationMemory, customerMessage) {
    try {
      const customerProfile = CustomerResolver.resolveProfile(customerData, conversationMemory);
      // Format as string manually if PromptService is async and we are in sync method, 
      // BUT this method is called synchronously in buildAdvancedPrompt, so we need to return { prompt: string, isNewCustomer: bool }
      // Wait, buildAdvancedPrompt line 358: const { prompt: customerPrompt, isNewCustomer } = this._getCustomerContext(...)

      let prompt = '';

      const sanitizedName = PromptService.sanitizeInput(customerProfile.name || 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯');
      const sanitizedCity = PromptService.sanitizeInput(customerProfile.city || '');
      const sanitizedPhone = PromptService.sanitizeInput(customerProfile.phone || '');

      // Fallback to simple string formatting for sync context
      prompt += `ğŸ‘¤ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„:\n`;
      prompt += `- Ø§Ù„Ø§Ø³Ù…: ${sanitizedName}\n`;
      if (sanitizedPhone) prompt += `- Ø§Ù„Ù‡Ø§ØªÙ: ${sanitizedPhone}\n`;
      if (sanitizedCity) prompt += `- Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©: ${sanitizedCity}\n`;
      prompt += `\n`;

      return { prompt, isNewCustomer: customerProfile.isNewCustomer };
    } catch (error) {
      console.warn('âš ï¸ [_getCustomerContext] Error:', error.message);
      return { prompt: '', isNewCustomer: false };
    }
  }

  /**
   * ğŸ”’ Helper: Get Reply Context
   */
  _getReplyContext(messageData, customerMessage) {
    let prompt = '';
    if (messageData?.replyContext?.isReply) {
      // Simple formatting without async template
      prompt += `â†©ï¸ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø±Ø¯:\n`;
      if (messageData.replyContext.originalMessage?.content) {
        const sanitizedOriginal = PromptService.sanitizeInput(messageData.replyContext.originalMessage.content);
        prompt += `- Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠØ±Ø¯ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„ØªÙƒ: "${sanitizedOriginal}"\n`;
      } else {
        prompt += `- Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠØ±Ø¯ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© Ø³Ø§Ø¨Ù‚Ø© Ù„Ùƒ\n`;
      }
      prompt += `\n`;
    }
    return prompt;
  }

  /**
   * ğŸ”’ Helper: Get Conversation History
   */
  async _getConversationHistory(conversationMemory, ragData, customerMessage) {
    // Called with await in buildAdvancedPrompt Line 365
    try {
      const historyData = CustomerResolver.resolveHistory(conversationMemory);
      let prompt = '';
      let lastMentionedProduct = null;

      if (historyData.hasHistory) {
        // Use PromptService since this method is async
        prompt += await PromptService.getTemplate(null, 'system_conversation_header');
        for (const item of historyData.items) {
          const timeAgo = this.aiAgentService.getTimeAgo(new Date(item.timestamp));
          const sender = item.sender === 'Customer' ? 'Ø§Ù„Ø¹Ù…ÙŠÙ„' : 'Ø±Ø¯Ùƒ';
          const sanitizedContent = PromptService.sanitizeInput(item.content);
          prompt += `${item.index}. ${sender} (Ù…Ù†Ø° ${timeAgo}): ${sanitizedContent}\n`;
        }
        prompt += await PromptService.getTemplate(null, 'system_conversation_footer');
      } else {
        prompt += await PromptService.getTemplate(null, 'system_first_interaction');
      }
      return { prompt, lastMentionedProduct };
    } catch (error) {
      console.warn('âš ï¸ [_getConversationHistory] Error:', error.message);
      return { prompt: '', lastMentionedProduct: null };
    }
  }

  /**
   * ğŸ”’ Helper: Get RAG Context
   */
  async _getRAGContext(ragData, smartResponseInfo, hasImages, isPostProductResponse) {
    // Called with await in buildAdvancedPrompt Line 382
    try {
      const ragContext = RagResolver.resolve(ragData);
      let prompt = '';

      // ğŸ” DEBUG: Log RAG context
      console.log(`ğŸ”ğŸ”ğŸ” [RAG-CONTEXT] hasData=${ragContext.hasData}, hasProducts=${ragContext.hasProducts}, items=${ragContext.items?.length || 0}`);
      if (ragContext.hasData && ragContext.items?.length > 0) {
        console.log(`ğŸ”ğŸ”ğŸ” [RAG-CONTEXT] First item: type=${ragContext.items[0].type}, name=${ragContext.items[0].metadata?.name || 'N/A'}`);
      }

      if (ragContext.hasData) {
        prompt += await PromptService.getTemplate(null, 'system_rag_header');
        for (const item of ragContext.items) {
          if (item.type === 'product') {
            prompt += await PromptService.getTemplate(null, 'system_rag_product', { index: item.index, content: item.content });
          } else if (item.type === 'faq') {
            prompt += await PromptService.getTemplate(null, 'system_rag_faq', { index: item.index, content: item.content });
          } else if (item.type === 'policy') {
            prompt += await PromptService.getTemplate(null, 'system_rag_policy', { index: item.index, content: item.content });
          }
        }
        prompt += await PromptService.getTemplate(null, 'system_rag_footer');
      } else {
        prompt += await PromptService.getTemplate(null, 'system_instructions_no_rag');
      }

      return prompt;
    } catch (error) {
      console.warn('âš ï¸ [_getRAGContext] Error:', error.message);
      return '';
    }
  }
}

module.exports = ResponseGenerator;
